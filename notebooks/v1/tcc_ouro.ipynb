{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fd0c2d",
   "metadata": {},
   "source": [
    "# TCC\n",
    "\n",
    "- Problema: localização de minérios\n",
    "- Solução: aplicação de aprendizado de máquina com uso de dados de espectrometria e gravimetria para classificar locais com alta probabilidade de conter minérios\n",
    "  - Minério de estudo: ouro\n",
    "\n",
    "---\n",
    "- Processamento:\n",
    "  - Problemas: \n",
    "    - conversão de coordenadas para latitude/longitude e uso de 2 casas decimais para evitar perda de dados durante mesclagem de dados\n",
    "\n",
    "  - Aprendizado de máquina:\n",
    "    - desbalanceamento entre classes\n",
    "\n",
    "---\n",
    "\n",
    "Ref Github: https://github.com/lszam/mineralexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f05cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from warnings import filterwarnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "import shap\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "sys.tracebacklimit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c88893",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_projeto = Path(os.getcwd()).parent.absolute().parent.absolute()\n",
    "data_dir = Path(dir_projeto, \"Output\", \"tcc\", \"v1\")\n",
    "shp_dir = Path(data_dir, \"shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arredondamento de casas decimais para conversão de coordenadas geográficas\n",
    "arredondamento = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea14318",
   "metadata": {},
   "source": [
    "## funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55fb867",
   "metadata": {},
   "source": [
    "### coordenadas geográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_to_latlon(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str = \"X\",\n",
    "    y_col: str = \"Y\",\n",
    "    utm_zone: int = 22,\n",
    "    southern_hemisphere: bool = True,\n",
    "    arredondamento: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert UTM coordinates to latitude/longitude (WGS84)\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing coordinates\n",
    "    - x_col: Column name for easting (UTM X)\n",
    "    - y_col: Column name for northing (UTM Y)\n",
    "    - utm_zone: UTM zone number (Brazil is mostly zones 22-25)\n",
    "    - southern_hemisphere: True for southern hemisphere (Brazil)\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with new 'longitude' and 'latitude' columns\n",
    "    \"\"\"\n",
    "    # Create UTM coordinate system\n",
    "    utm = pyproj.Proj(proj=\"utm\", zone=utm_zone, south=southern_hemisphere)\n",
    "\n",
    "    # Create WGS84 coordinate system\n",
    "    wgs84 = pyproj.Proj(proj=\"latlong\", datum=\"WGS84\")\n",
    "\n",
    "    # Convert coordinates\n",
    "    lon, lat = pyproj.transform(utm, wgs84, df[x_col].values, df[y_col].values)\n",
    "\n",
    "    # Add to DataFrame\n",
    "    df = df.copy()\n",
    "    df[\"longitude\"] = lon\n",
    "    df[\"latitude\"] = lat\n",
    "\n",
    "    df[\"longitude\"] = df[\"longitude\"].round(arredondamento)\n",
    "    df[\"latitude\"] = df[\"latitude\"].round(arredondamento)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_shapefile_to_latlon(shapefile_path: Path) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Read a shapefile and convert coordinates to latitude/longitude (WGS84)\n",
    "\n",
    "    Parameters:\n",
    "    - shapefile_path: path for the shapefile\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    if gdf.crs is None:\n",
    "        # Assuming it's in the same UTM as your other data\n",
    "        gdf.crs = \"+proj=utm +zone=22 +south +datum=WGS84 +units=m +no_defs\"\n",
    "    gdf = gdf.to_crs(epsg=4326)  # Convert to WGS84 (lat/lon)\n",
    "    if not os.path.basename(shapefile_path) == \"estruturas_ln.shp\":\n",
    "        gdf[\"longitude\"] = gdf.geometry.x\n",
    "        gdf[\"latitude\"] = gdf.geometry.y\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d48f6",
   "metadata": {},
   "source": [
    "### processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterizar_coordenadas_geograficas(df: pd.DataFrame, n_clusters: np.int16 = 8) -> pd.DataFrame:\n",
    "    \"\"\"Aplica clusterização nas coordenadas geográficas para modelo de aprendizado de máquina,\n",
    "    como feature engineering\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe com dados de coordenadas geográficas\n",
    "        n_clusters (np.int16, optional): número de clusters. Defaults to 8.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe com clusters de coordenadas\n",
    "    \"\"\"\n",
    "    coords = df[[\"longitude\", \"latitude\"]].values\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords)\n",
    "    df[\"geo_cluster\"] = kmeans.labels_\n",
    "    dict_map_idx_lon = dict(zip(df.index, df[\"longitude\"]))\n",
    "    dict_map_idx_lat = dict(zip(df.index, df[\"latitude\"]))\n",
    "    df = df.drop([\"longitude\", \"latitude\"], axis=1)\n",
    "    return df, dict_map_idx_lon, dict_map_idx_lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e62e14",
   "metadata": {},
   "source": [
    "### aprendizado de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3aad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size: np.float16 = 0.3) -> tuple:\n",
    "    \"\"\"Divide dados de treino e teste\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe com dados\n",
    "        test_size (np.float16, optional): tamanho dos dados de teste. Defaults to 0.3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: _description_\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        random_state=420,\n",
    "        stratify=y,  # dados desbalanceados\n",
    "    )\n",
    "\n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "    print(f\"Class balance - Train: {y_train.mean():.2%}, Test: {y_test.mean():.2%}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml(\n",
    "    models: dict,\n",
    "    cv: StratifiedKFold,\n",
    "    X_train: np.array,\n",
    "    X_test: np.array,\n",
    "    y_train: np.array,\n",
    "    y_test: np.array,\n",
    ") -> dict:\n",
    "    \"\"\"Pipeline para modelos de aprendizado de máquina, realizando treinamento com validação cruzada e avaliação\n",
    "\n",
    "    Args:\n",
    "        models (dict): dicionário com modelos\n",
    "        cv (StratifiedKFold): validação cruzada\n",
    "        X_train (np.array): array de dados independentes de treino\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_train (np.array): array de dados dependentes de treino\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline (scale for logistic regression)\n",
    "        if name == \"Logistic Regression\":\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            pipe = model\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"Tempo total de treino {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\"model\": pipe, \"cv_mean_auc\": cv_scores.mean(), \"cv_std_auc\": cv_scores.std()}\n",
    "\n",
    "        print(f\"{name} - CV AUC: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "\n",
    "        # Evaluate on test set\n",
    "        if hasattr(pipe, \"predict_proba\"):\n",
    "            evaluate_model(pipe, X_test, y_test)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: np.array, y_test: np.array) -> None:\n",
    "    \"\"\"Função para avaliar o modelo\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\nOptimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def evaluate_model_custom(model, X_test: np.array, y_test: np.array, threshold: float) -> None:\n",
    "    \"\"\"Função para avaliar o modelo\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_custom = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred_custom):.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_custom))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\nOptimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_undersampling(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "    # Training and evaluation\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Tempo total de treino {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"model\": pipeline,\n",
    "            \"cv_mean_auc\": cv_scores.mean(),\n",
    "            \"cv_std_auc\": cv_scores.std(),\n",
    "        }\n",
    "\n",
    "        # Test set evaluation\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "            print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "            print(f\"Test F1 Score: {f1:.3f}\")\n",
    "            print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Find optimal threshold\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "            # Store additional metrics\n",
    "            results[name].update({\n",
    "                \"test_roc_auc\": roc_auc,\n",
    "                \"test_f1\": f1,\n",
    "                \"test_avg_precision\": avg_precision,\n",
    "                \"optimal_threshold\": optimal_threshold,\n",
    "            })\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "        print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "        print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "        print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_oversampling(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    min_minority_samples = min([\n",
    "        np.sum(y_train[test_idx] == 1) for _, test_idx in cv.split(X_train, y_train)\n",
    "    ])\n",
    "\n",
    "    k_neighbors = min(5, min_minority_samples - 1) if min_minority_samples > 1 else 1\n",
    "\n",
    "    # Training and evaluation\n",
    "    for name, model in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline with SMOTE\n",
    "        pipeline = ImbPipeline([\n",
    "            (\"smote\", SMOTE(random_state=42, sampling_strategy=\"auto\", k_neighbors=k_neighbors)),\n",
    "            (\"classifier\", model),\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(\n",
    "                pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1, error_score=\"raise\"\n",
    "            )\n",
    "\n",
    "            # Full training\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "            print(f\"Training time {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                \"model\": pipeline,\n",
    "                \"cv_mean_auc\": cv_scores.mean(),\n",
    "                \"cv_std_auc\": cv_scores.std(),\n",
    "            }\n",
    "\n",
    "            print(f\"CV AUC: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "\n",
    "            # Test set evaluation\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                # Calculate metrics\n",
    "                roc_auc = roc_auc_score(y_test, y_proba)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "                print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "                print(f\"Test F1 Score: {f1:.3f}\")\n",
    "                print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "\n",
    "                # Find optimal threshold\n",
    "                precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "                f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "                optimal_idx = np.argmax(f1_scores)\n",
    "                optimal_threshold = thresholds[optimal_idx]\n",
    "                print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "                # Store additional metrics\n",
    "                results[name].update({\n",
    "                    \"test_roc_auc\": roc_auc,\n",
    "                    \"test_f1\": f1,\n",
    "                    \"test_avg_precision\": avg_precision,\n",
    "                    \"optimal_threshold\": optimal_threshold,\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to train {name}: {str(e)}\")\n",
    "            results[name] = {\"error\": str(e)}\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        if \"error\" in res:\n",
    "            print(f\"Training failed: {res['error']}\")\n",
    "        else:\n",
    "            print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "            if \"test_roc_auc\" in res:\n",
    "                print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "                print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "                print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80667d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_smote_tomek(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    # Training and evaluation\n",
    "    for name, model in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline with SMOTETomek\n",
    "        pipeline = ImbPipeline([\n",
    "            (\n",
    "                \"smote_tomek\",\n",
    "                SMOTETomek(\n",
    "                    random_state=42,\n",
    "                    tomek=TomekLinks(sampling_strategy=\"majority\"),\n",
    "                    smote=SMOTE(k_neighbors=2),  # Reduce from default 5\n",
    "                ),\n",
    "            ),\n",
    "            (\"classifier\", model),\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(\n",
    "            f\"Total training time for {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\"\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"model\": pipeline,\n",
    "            \"cv_mean_auc\": cv_scores.mean(),\n",
    "            \"cv_std_auc\": cv_scores.std(),\n",
    "        }\n",
    "\n",
    "        # Test set evaluation\n",
    "        if hasattr(model, \"predict_proba\"):  # Check the original model for predict_proba\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "            print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "            print(f\"Test F1 Score: {f1:.3f}\")\n",
    "            print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Find optimal threshold\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "            # Store additional metrics\n",
    "            results[name].update({\n",
    "                \"test_roc_auc\": roc_auc,\n",
    "                \"test_f1\": f1,\n",
    "                \"test_avg_precision\": avg_precision,\n",
    "                \"optimal_threshold\": optimal_threshold,\n",
    "            })\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "        if \"test_roc_auc\" in res:\n",
    "            print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "            print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "            print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed50d07",
   "metadata": {},
   "source": [
    "## leitura e processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3075ed",
   "metadata": {},
   "source": [
    "- leitura dos shapefiles com ocorrências de metais/minas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38260a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouro = gpd.read_file(Path(shp_dir, 'ocorrencias_Au.shp'))\n",
    "# # cobre = gpd.read_file(Path(shp_dir, 'ocorrencias_Cu.shp'))\n",
    "# ferro = gpd.read_file(Path(shp_dir, 'ocorrencias_Fe.shp'))\n",
    "# # manganes = gpd.read_file(Path(shp_dir, 'ocorrencias_Mn.shp'))\n",
    "# # niquel = gpd.read_file(Path(shp_dir, 'ocorrencias_Ni.shp'))\n",
    "# # chumbo = gpd.read_file(Path(shp_dir, 'ocorrencias_Pb.shp'))\n",
    "# # estanho = gpd.read_file(Path(shp_dir, 'ocorrencias_Sn.shp'))\n",
    "# minas = gpd.read_file(Path(shp_dir, 'minas.shp'))\n",
    "# estruturas = gpd.read_file(Path(shp_dir, 'estruturas_ln.shp'))\n",
    "\n",
    "# ! leitura dos arquivos com conversão para latitude/longitude\n",
    "ouro = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Au.shp\"))\n",
    "cobre = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Cu.shp\"))\n",
    "ferro = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Fe.shp\"))\n",
    "# manganes = convert_shapefile_to_latlon(Path(shp_dir, 'ocorrencias_Mn.shp'))\n",
    "niquel = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Ni.shp\"))\n",
    "chumbo = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Pb.shp\"))\n",
    "# estanho = convert_shapefile_to_latlon(Path(shp_dir, 'ocorrencias_Sn.shp'))\n",
    "\n",
    "minas = convert_shapefile_to_latlon(Path(shp_dir, \"minas.shp\"))\n",
    "\n",
    "estruturas = convert_shapefile_to_latlon(Path(shp_dir, \"estruturas_ln.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34065dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/api/markers_api.html\n",
    "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ouro.plot(ax=ax, color=\"orange\", marker=\"*\", markersize=50, label=\"Ouro\")\n",
    "cobre.plot(ax=ax, color=\"lightcoral\", marker=\"x\", markersize=50, label=\"Cobre\")\n",
    "ferro.plot(ax=ax, color=\"gray\", marker=\"v\", markersize=50, label=\"Ferro\")\n",
    "chumbo.plot(ax=ax, color=\"lightsteelblue\", marker=\"s\", markersize=50, label=\"Chumbo\")\n",
    "niquel.plot(ax=ax, color=\"green\", marker=\"p\", markersize=50, label=\"Níquel\")\n",
    "minas.plot(ax=ax, color=\"blue\", marker=\"o\", markersize=50, label=\"Minas\")\n",
    "# estruturas.plot(ax=ax, color='blue', alpha=0.5, label='Estruturas')\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minas = pd.DataFrame(minas)\n",
    "df_minas = df_minas[[\"longitude\", \"latitude\"]]\n",
    "df_minas[\"longitude\"] = df_minas[\"longitude\"].round(arredondamento)\n",
    "df_minas[\"latitude\"] = df_minas[\"latitude\"].round(arredondamento)\n",
    "\n",
    "df_minas.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouro, cobre, ferro, manganes, niquel, chumbo, estanho\n",
    "df_minerio = pd.DataFrame(ouro)\n",
    "df_minerio = df_minerio[[\"longitude\", \"latitude\"]]\n",
    "df_minerio[\"longitude\"] = df_minerio[\"longitude\"].round(arredondamento)\n",
    "df_minerio[\"latitude\"] = df_minerio[\"latitude\"].round(arredondamento)\n",
    "df_minerio = df_minerio.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "df_minerio[\"ocorrencia\"] = 1\n",
    "\n",
    "print(df_minerio.shape)\n",
    "df_minerio.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4c85b",
   "metadata": {},
   "source": [
    "- leitura dos dados de espectrometria\n",
    "\n",
    "  - dados:\n",
    "    - Fator F: parâmetro de Efimov (valores altos para rochas alteradas por fluidos que carregam metais)\n",
    "    - Kd: abundância de potássio normalizado pelo tório\n",
    "    - Ud: abundância de urânio normalizado pelo tório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d653214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = pd.read_csv(\n",
    "    Path(data_dir, \"dados_gamaespectrometria_filtrados.csv\"),\n",
    "    dtype={\n",
    "        \"XUTM\": np.float32,\n",
    "        \"YUTM\": np.float32,\n",
    "        \"FatorF\": np.float32,\n",
    "        \"Kd\": np.float32,\n",
    "        \"Ud\": np.float32,\n",
    "    },\n",
    ")\n",
    "# spec_data.rename(columns={\"XUTM\": \"X\", \"YUTM\": \"Y\"}, inplace=True)\n",
    "spec_data = utm_to_latlon(spec_data, x_col=\"XUTM\", y_col=\"YUTM\", arredondamento=arredondamento)\n",
    "spec_data = spec_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "spec_data = spec_data.drop([\"XUTM\", \"YUTM\"], axis=1)\n",
    "print(spec_data.shape)\n",
    "spec_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076fd34",
   "metadata": {},
   "source": [
    "- leitura dos dados de gravimetria\n",
    "\n",
    "  - dados:\n",
    "    - grav_residual190km_qht: gravidade residual a 190 km\n",
    "    - grav_residual100km: gravidade residual a 100 km\n",
    "    - maq_asvi: amplitude do sinal analítico da integral vertical do campo magnético\n",
    "    - maq_qt: gradiente total do campo magnético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_data = pd.read_csv(\n",
    "    Path(data_dir, \"dados_gravmag_filtrados_v2.csv\"),\n",
    "    dtype={\n",
    "        \"X\": np.float32,\n",
    "        \"Y\": np.float32,\n",
    "        \"grav_residual190km_ght\": np.float32,\n",
    "        \"grav_residual100km\": np.float32,\n",
    "        \"mag_asvi\": np.float32,\n",
    "        \"mag_gt\": np.float32,\n",
    "    },\n",
    ")\n",
    "grav_data = utm_to_latlon(grav_data, x_col=\"X\", y_col=\"Y\", arredondamento=arredondamento)\n",
    "grav_data = grav_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "grav_data = grav_data.drop([\"X\", \"Y\"], axis=1)\n",
    "print(grav_data.shape)\n",
    "grav_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee24b1",
   "metadata": {},
   "source": [
    "- mesclar dfs com dados de gravimetria e espectrometria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_data = pd.merge(spec_data, grav_data, how=\"inner\", on=[\"longitude\", \"latitude\"])\n",
    "df_merge_data = df_merge_data[\n",
    "    [\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"FatorF\",\n",
    "        \"Kd\",\n",
    "        \"Ud\",\n",
    "        \"grav_residual190km_ght\",\n",
    "        \"grav_residual100km\",\n",
    "        \"mag_asvi\",\n",
    "        \"mag_gt\",\n",
    "    ]\n",
    "]\n",
    "df_merge_data = df_merge_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "print(df_merge_data.shape)\n",
    "df_merge_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcc16a",
   "metadata": {},
   "source": [
    "- criar dataframes base para aprendizado de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! aplica knn para pontos de ocorrência de ouro mais próximos\n",
    "# coords_merge = df_merge_data_reduced[[\"longitude\", \"latitude\"]].values\n",
    "# coords_minerio = df_minerio[[\"longitude\", \"latitude\"]].values\n",
    "\n",
    "# nbrs = NearestNeighbors(n_neighbors=1).fit(coords_merge)\n",
    "# distances, indices = nbrs.kneighbors(coords_minerio)\n",
    "\n",
    "# df_minerio_merge = df_merge_data_reduced.copy()\n",
    "# df_minerio_merge[\"ocorrencia\"] = 0\n",
    "\n",
    "# for pos in indices.flatten():\n",
    "#     df_minerio_merge.loc[pos, \"ocorrencia\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4736c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape do merge == df_minerio -> garantia de que há os mesmos pontos\n",
    "pd.merge(df_merge_data, df_minerio, how=\"inner\", on=[\"longitude\", \"latitude\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria df com inner join\n",
    "df_minerio_inner = pd.merge(df_merge_data, df_minerio, how=\"inner\", on=[\"longitude\", \"latitude\"])\n",
    "print(df_minerio_inner.shape)\n",
    "df_minerio_inner.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c10ef2",
   "metadata": {},
   "source": [
    "- Muitos pontos na base de dados -> desbalanço muito forte de classes\n",
    "    - Redução da base: corte da área e reamostragem da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mesclagem de dados (espec + gravim): {df_merge_data.shape[0]}\")\n",
    "print(f\"Mesclagem de dados (espec + gravim): {df_minerio.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(df_merge_data['longitude'], df_merge_data['latitude'], label='Grade Mescalada')\n",
    "ax.scatter(df_minerio['longitude'], df_minerio['latitude'], color='orange', label='Ocorrências de Ouro')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redução da área geográfica\n",
    "min_lat, max_lat = df_minerio['latitude'].min(), df_minerio['latitude'].max()\n",
    "min_lon, max_lon = df_minerio['longitude'].min(), df_minerio['longitude'].max()\n",
    "\n",
    "padding = 0.1\n",
    "lat_min_padded = min_lat - padding\n",
    "lat_max_padded = max_lat + padding\n",
    "lon_min_padded = min_lon - padding\n",
    "lon_max_padded = max_lon + padding\n",
    "\n",
    "df_merge_data_clipped = df_merge_data[\n",
    "    (df_merge_data['latitude'] >= lat_min_padded) & (df_merge_data['latitude'] <= lat_max_padded) &\n",
    "    (df_merge_data['longitude'] >= lon_min_padded) & (df_merge_data['longitude'] <= lon_max_padded)\n",
    "]\n",
    "\n",
    "# reamostragem dos dados via pandas\n",
    "df_merge_data_reduced = df_merge_data_clipped.sample(frac=0.03, random_state=42)\n",
    "\n",
    "print(df_merge_data_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f751bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatena inner join com reamostragem\n",
    "df_minerio_merge = pd.concat([df_merge_data_reduced, df_minerio_inner], axis=0, ignore_index=True)\n",
    "df_minerio_merge = df_minerio_merge.fillna(0)\n",
    "df_minerio_merge['ocorrencia'] = df_minerio_merge['ocorrencia'].astype(int)\n",
    "print(df_merge_data_reduced.shape)\n",
    "df_minerio_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75203b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 0][\"longitude\"],\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 0][\"latitude\"],\n",
    "    label=\"Grade Mescalada\",\n",
    ")\n",
    "ax.scatter(\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 1][\"longitude\"],\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 1][\"latitude\"],\n",
    "    color=\"orange\",\n",
    "    label=\"Ocorrências de Ouro\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890761de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dados de espectrometria: {spec_data.shape[0]}\")\n",
    "print(f\"Dados de gravimetria: {grav_data.shape[0]}\")\n",
    "print(f\"Mesclagem de dados (espec + gravim): {df_merge_data.shape[0]}\")\n",
    "print(f\"Redução de mesclagem de dados (espec + gravim): {df_merge_data_reduced.shape[0]}\")\n",
    "print(f\"Mesclagem com ouro (espec + gravim + ouro): {df_minerio_merge.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 4))\n",
    "ax = sns.countplot(x=\"ocorrencia\", data=df_minerio_merge, palette=\"pastel\")\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Ouro:\",\n",
    "    round(df_minerio_merge[\"ocorrencia\"].value_counts()[1] / len(df_minerio_merge) * 100, 2),\n",
    "    \"% do dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922109b",
   "metadata": {},
   "source": [
    "- clusterização de coordenadas geográficas\n",
    "  - n_clusters = default 8 (tutorial) -> parametrizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minerio_merge, dict_map_idx_lon, dict_map_idx_lat = clusterizar_coordenadas_geograficas(\n",
    "    df=df_minerio_merge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e821f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minerio_merge = df_minerio_merge[\n",
    "    [\n",
    "        \"geo_cluster\",\n",
    "        \"FatorF\",\n",
    "        \"Kd\",\n",
    "        \"Ud\",\n",
    "        \"grav_residual190km_ght\",\n",
    "        \"grav_residual100km\",\n",
    "        \"mag_asvi\",\n",
    "        \"mag_gt\",\n",
    "        \"ocorrencia\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975c2c4",
   "metadata": {},
   "source": [
    "## aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e8eec",
   "metadata": {},
   "source": [
    "### split treino-teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724df17",
   "metadata": {},
   "source": [
    "- split padrão -> 70% treino e 30% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2adf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_minerio_merge.drop([\"ocorrencia\"], axis=1)\n",
    "y = df_minerio_merge[\"ocorrencia\"].values\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e500fbd",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = pipeline_ml(models, cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2539f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Melhor desempenho geral: Teve o maior AUC médio (0.774) e ROC-AUC (0.785), indicando boa capacidade de distinguir entre as classes.\n",
    "\n",
    "    - Problema com a classe minoritária (1): Apesar do bom AUC, o F1-Score para a classe 1 foi baixo (0.222), mostrando dificuldade em prever corretamente os casos positivos (baixo recall: 0.14). O modelo priorizou a classe majoritária (0), como visto na alta precisão (0.50) mas baixo recall.\n",
    "\n",
    "    - Threshold baixo (0.28): Sugere que o modelo atribui probabilidades baixas à classe 1, exigindo ajuste para melhorar o equilíbrio.\n",
    "\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Desempenho ruim: AUC médio (0.539) e ROC-AUC (0.492) próximos de 0.5 (aleatoriedade). F1-Score muito baixo (0.059) para a classe 1.\n",
    "\n",
    "    - Problema de viés: Alto recall (0.43) para a classe 1, mas precisão extremamente baixa (0.03), indicando muitos falsos positivos.\n",
    "\n",
    "\n",
    "- SVM\n",
    "\n",
    "    - Pior modelo: AUC médio (0.453) e ROC-AUC (0.335) abaixo de 0.5, indicando desempenho pior que aleatório. F1-Score baixíssimo (0.073).\n",
    "\n",
    "    - Overfitting na classe 1: Recall altíssimo (0.86) mas precisão muito baixa (0.04), gerando muitos falsos positivos. Threshold muito baixo (0.041) mostra que o modelo quase sempre classifica como positivo.\n",
    "\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - Melhor F1-Score para classe 1: Teve o maior F1-Score (0.462) para a classe minoritária, com recall (0.43) e precisão (0.50) equilibrados.\n",
    "\n",
    "    - Bom AUC: AUC médio (0.711) e ROC-AUC (0.777) próximos ao Random Forest, mas com melhor balanceamento entre as classes.\n",
    "\n",
    "    - Threshold alto (0.97): Indica que o modelo só classifica como positivo quando tem alta confiança, reduzindo falsos positivos.\n",
    "\n",
    "---\n",
    "\n",
    "- Problema Principal: Desbalanceamento de Classes\n",
    "\n",
    "    - Todos os modelos, exceto XGBoost, ignoraram a classe minoritária.\n",
    "\n",
    "    - AUC médio razoável (especialmente XGBoost e Random Forest), mas F1 Score muito baixo para a classe 1.\n",
    "\n",
    "    - Solução possível: Usar técnicas como reesampling (SMOTE, undersampling), ajustar pesos das classes ou otimizar thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 4, figsize=(10, 4))\n",
    "# for mdl, ax in zip(models.keys(), axs.flatten()):\n",
    "#     y_proba = models[mdl].predict_proba(X_test)[:, 1]\n",
    "#     fpr, tpr, threshold = roc_curve(y_test, y_proba)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # plot\n",
    "#     ax.plot(fpr, tpr, label=\"AUC={}\".format(round(roc_auc, 2)))\n",
    "#     ax.plot([0, 1], [0, 1], \"r--\")\n",
    "#     ax.legend()\n",
    "#     ax.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "#     ax.set_title(mdl)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb24f2",
   "metadata": {},
   "source": [
    "- Soluções:\n",
    "  - Existem diferentes soluções:\n",
    "    - undersampling da classe majoritária (0)\n",
    "    - oversampling da classe minoritária (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc0be2",
   "metadata": {},
   "source": [
    "### pipeline undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Create pipelines with undersampling\n",
    "pipelines_unders = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Adiciona StandardScaler para modelos sensíveis à escala\n",
    "        pipelines_unders[name] = make_pipeline(\n",
    "            RandomUnderSampler(random_state=42), StandardScaler(), model\n",
    "        )\n",
    "    else:\n",
    "        pipelines_unders[name] = make_pipeline(RandomUnderSampler(random_state=42), model)\n",
    "\n",
    "results_unders = pipeline_ml_undersampling(pipelines_unders, cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdde3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Melhor ROC-AUC (0.784) e F1 (0.108) entre os modelos.\n",
    "\n",
    "    - Trade-off claro: Recall alto para classe 1 (71%), mas precisão muito baixa (6%).\n",
    "\n",
    "    - Threshold alto (0.83) sugere que o modelo é conservador para prever a classe 1.\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Resultados medianos (ROC-AUC 0.661), mas com o mesmo problema: precisão baixíssima (5%) para classe 1.\n",
    "\n",
    "    - Threshold ainda mais alto (0.844), indicando cautela excessiva.\n",
    "\n",
    "- SVM\n",
    "\n",
    "    - ROC-AUC catastrófico (0.223) no teste, apesar do CV AUC razoável (0.726).\n",
    "\n",
    "    - Recall 100% para classe 1, mas com precisão de apenas 5% – praticamente um \"chute cego\".\n",
    "\n",
    "    - Threshold baixo (0.338) mostra que o SVM está superajustado ao undersampling.\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - ROC-AUC alto (0.779), mas F1 igual aos outros (0.092).\n",
    "\n",
    "    - Recall altíssimo (86%) para classe 1, mas precisão muito baixa (5%).\n",
    "\n",
    "    - Threshold quase máximo (0.998) indica que o modelo raramente classifica como classe 1.\n",
    "\n",
    "---\n",
    "\n",
    "- Problemas Identificados\n",
    "\n",
    "    - Overfitting ao undersampling: SVM e XGBoost têm thresholds extremos (0.338 e 0.998), sugerindo que podem estar capturando ruídos.\n",
    "\n",
    "    - Precisão/Recall desbalanceados: O undersampling melhorou o recall da classe 1, mas a precisão ficou inutilizável (5–6%).\n",
    "\n",
    "    - Acurácia geral caiu: Em alguns modelos (como SVM), a acurácia despencou para 36%, pois muitas previsões da classe 0 estão erradas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686bc9c",
   "metadata": {},
   "source": [
    "### pipeline oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Create pipelines with overrsampling\n",
    "pipelines_overs = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Add StandardScaler for Logistic Regression\n",
    "        pipelines_overs[name] = make_pipeline(StandardScaler(), model)\n",
    "    else:\n",
    "        pipelines_overs[name] = make_pipeline(model)\n",
    "\n",
    "results_overs = pipeline_ml_oversampling(\n",
    "    pipelines=pipelines_overs, cv=cv, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91175337",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Random Forest: Melhor F1-Score (0.40)\n",
    "\n",
    "    ROC-AUC razoável (0.698), mas menor que no undersampling (0.784).\n",
    "\n",
    "    Precisão (38%) e recall (43%) mais equilibrados para a classe 1.\n",
    "\n",
    "    Threshold mais baixo (0.55), indicando maior disposição para prever a classe 1.\n",
    "\n",
    "    Acurácia geral alta (96%), mas ainda com dificuldade na classe minoritária.\n",
    "\n",
    "2. XGBoost: Melhor ROC-AUC (0.751) e F1 Aceitável (0.27)\n",
    "\n",
    "    Recall razoável (43%), mas precisão baixa (20%) para a classe 1.\n",
    "\n",
    "    Threshold = 1.0 sugere que o modelo é extremamente conservador (quase nunca classifica como classe 1).\n",
    "\n",
    "    Desempenho geral melhor que SVM e Regressão Logística, mas ainda abaixo do Random Forest em F1.\n",
    "\n",
    "3. SVM: Melhorou em relação ao undersampling, mas ainda problemático\n",
    "\n",
    "    ROC-AUC aceitável (0.694), mas F1 ainda baixo (0.21).\n",
    "\n",
    "    Recall alto (57%), mas precisão muito baixa (13%) → Muitos falsos positivos.\n",
    "\n",
    "    Threshold extremo (0.997), indicando que o modelo raramente classifica como classe 1.\n",
    "\n",
    "4. Regressão Logística: Desempenho Ruim\n",
    "\n",
    "    ROC-AUC muito baixo (0.484), próximo de aleatoriedade.\n",
    "\n",
    "    F1 Score insignificante (0.06).\n",
    "\n",
    "    Recall razoável (43%), mas precisão inútil (3%) → Praticamente inaplicável.\n",
    "\n",
    "---\n",
    "\n",
    "- Comparação com Undersampling\n",
    "\n",
    "    - Vantagem do SMOTE:\n",
    "\n",
    "        - Melhor equilíbrio entre precisão e recall (Random Forest: 38% precisão e 43% recall vs. undersampling: 6% precisão e 71% recall).\n",
    "\n",
    "        - Menos perda de desempenho na classe majoritária (acurácia geral melhor mantida).\n",
    "\n",
    "    - Desvantagem do SMOTE:\n",
    "\n",
    "        - AUC geralmente menor que no undersampling (possível introdução de ruído sintético).\n",
    "\n",
    "        - Precisão ainda baixa para a classe 1 (20-38%), indicando muitos falsos positivos.\n",
    "\n",
    "---\n",
    "\n",
    "- Problemas Persistentes\n",
    "\n",
    "    - Classe 1 ainda difícil de prever: Mesmo com SMOTE, a precisão é baixa, o que pode ser inaceitável dependendo do custo de falsos positivos.\n",
    "\n",
    "    - Thresholds extremos em XGBoost e SVM: Se o modelo quase nunca classifica como classe 1, ele pode ser inútil na prática.\n",
    "\n",
    "    - Regressão Logística falhou completamente, sugerindo que modelos lineares podem não ser adequados para esse problema.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80bbec",
   "metadata": {},
   "source": [
    "### pipeline combinação oversampling + undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c987e",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "pipelines_comb = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Add StandardScaler for Logistic Regression\n",
    "        pipelines_comb[name] = make_pipeline(StandardScaler(), model)\n",
    "    else:\n",
    "        pipelines_comb[name] = make_pipeline(model)\n",
    "\n",
    "results_smote_tomek = pipeline_ml_smote_tomek(\n",
    "    pipelines=pipelines_comb, cv=cv, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd448d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "1. Random Forest: Melhor Compromisso (F1 = 0.375)\n",
    "\n",
    "    - ROC-AUC menor (0.652) que no SMOTE puro (0.698), mas ainda aceitável.\n",
    "\n",
    "    - Precisão (33%) e recall (43%) equilibrados para a classe 1, semelhante ao SMOTE puro.\n",
    "\n",
    "    - Threshold moderado (0.62), indicando que o modelo está mais confiante que no SMOTE puro (0.55).\n",
    "\n",
    "    - Acurácia geral alta (95%), mantendo boa performance na classe majoritária.\n",
    "\n",
    "2. XGBoost: Melhor ROC-AUC (0.772), mas F1 ainda baixo (0.30)\n",
    "\n",
    "    - Recall razoável (43%), mas precisão muito baixa (23%) → Muitos falsos positivos.\n",
    "\n",
    "    - Threshold = 1.0 mostra que o modelo quase nunca classifica como classe 1, limitando sua utilidade prática.\n",
    "\n",
    "    - Melhor que SVM e Regressão Logística, mas ainda abaixo do Random Forest.\n",
    "\n",
    "3. SVM: Melhor que Regressão Logística, mas ainda problemático\n",
    "\n",
    "    - ROC-AUC aceitável (0.682), mas F1 baixo (0.195).\n",
    "\n",
    "    - Recall alto (57%), mas precisão muito baixa (12%) → Muitos falsos positivos.\n",
    "\n",
    "    - Threshold extremo (0.996) indica que o modelo raramente classifica como classe 1.\n",
    "\n",
    "4. Regressão Logística: Desempenho Inútil\n",
    "\n",
    "    - ROC-AUC próximo de aleatoriedade (0.494).\n",
    "\n",
    "    - F1 Score insignificante (0.065).\n",
    "\n",
    "    - Recall razoável (43%), mas precisão inaceitável (4%) → Modelo não confiável.\n",
    "\n",
    "---\n",
    "\n",
    "- Comparação com SMOTE Puro\n",
    "    \n",
    "    - SMOTE puro teve ROC-AUC e F1 ligeiramente melhores, mas SMOTE + Tomek Links levou a thresholds mais conservadores.\n",
    "\n",
    "    - Tomek Links pode ter removido instâncias ruidosas, mas não melhorou significativamente o trade-off precisão/recall.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- Precisão ainda baixa para a classe 1 (23-33%), indicando muitos falsos positivos.\n",
    "\n",
    "- Thresholds extremos em XGBoost e SVM → Modelos muito conservadores, perdendo casos da classe 1.\n",
    "\n",
    "- Regressão Logística continua ineficaz para esse problema.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370c96c",
   "metadata": {},
   "source": [
    "### melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04273f2",
   "metadata": {},
   "source": [
    "- Random Forest com Pipeline Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"classifier\", model),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Pipeline Sem Threshold Ótimo')\n",
    "evaluate_model(pipeline, X_test, y_test)\n",
    "\n",
    "print('\\nPipeline Com Threshold Ótimo')\n",
    "# Apply threshold\n",
    "# Optimal Decision Threshold: 0.970\n",
    "evaluate_model_custom(pipeline, X_test, y_test, 0.970)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45708f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "# Apply threshold\n",
    "# Optimal Decision Threshold: 0.550\n",
    "y_pred_custom = (y_proba >= 0.550).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2260151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class 1: {sum(y_pred == 0)}\")\n",
    "print(f\"Class 1 (Custom): {sum(y_pred_custom == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddd913",
   "metadata": {},
   "source": [
    "- feature importance do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pipeline.named_steps['classifier']\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Feature Importance\", fontsize=14)\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Gini Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot all this\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(fpr, tpr, label=\"AUC={}\".format(round(roc_auc, 2)))\n",
    "ax.plot([0, 1], [0, 1], \"r--\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Best Model ROC-AUC\")\n",
    "ax.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69974e",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f586f",
   "metadata": {},
   "source": [
    "Ref: https://shap.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ef3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer(X_train)\n",
    "shap_values_pos = shap_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d48433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape: {X_train.shape}\")\n",
    "print(f\"All SHAP values shape: {np.array(shap_values).shape}\")\n",
    "print(f\"SHAP values for class 1: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    pd.DataFrame(X_train, columns=X_train.columns),\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    plot_type=\"bar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7749b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values, pd.DataFrame(X_train, columns=X_train.columns), plot_type=\"violin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4daed",
   "metadata": {},
   "source": [
    "### Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_df = pd.DataFrame.from_dict(dict_map_idx_lon, orient=\"index\")\n",
    "coord_df[\"latitude\"] = dict_map_idx_lat\n",
    "coord_df.columns = [\"longitude\", \"latitude\"]\n",
    "coord_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92444f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = X_test.copy()\n",
    "results[\"probability\"] = y_proba\n",
    "results[\"prediction\"] = y_pred_custom\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30265c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(results, coord_df, left_index=True, right_index=True, how=\"inner\")\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d48abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral_locations = results[results[\"prediction\"] == 1]\n",
    "print(f\"Locais com alta confiança de ouro: {len(mineral_locations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python-visualization.github.io/folium/latest/user_guide/raster_layers/tiles.html\n",
    "fig = Figure(width=700, height=600)\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[mineral_locations[\"latitude\"].mean(), mineral_locations[\"longitude\"].mean()],\n",
    "    zoom_start=7,\n",
    ")\n",
    "\n",
    "for _, row in df_minas.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]], radius=5, color=\"red\", fill=True, tooltip=\"Mina\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "for _, row in df_minerio.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]], radius=5, color=\"orange\", fill=True, tooltip=\"Ouro\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "for _, row in mineral_locations.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=\"yellow\",\n",
    "        fill=True,\n",
    "        tooltip=f\"Ouro Prob: {row['probability']:.3f}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "fig.add_child(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
