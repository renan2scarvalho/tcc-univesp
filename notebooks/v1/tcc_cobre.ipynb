{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fd0c2d",
   "metadata": {},
   "source": [
    "# TCC\n",
    "\n",
    "- Problema: localização de minérios\n",
    "- Solução: aplicação de aprendizado de máquina com uso de dados de espectrometria e gravimetria para classificar locais com alta probabilidade de conter minérios\n",
    "  - Minério de estudo: cobre\n",
    "\n",
    "---\n",
    "- Processamento:\n",
    "  - Problemas: \n",
    "    - conversão de coordenadas para latitude/longitude e uso de 2 casas decimais para evitar perda de dados durante mesclagem de dados\n",
    "\n",
    "  - Aprendizado de máquina:\n",
    "    - desbalanceamento entre classes\n",
    "\n",
    "---\n",
    "\n",
    "Ref Github: https://github.com/lszam/mineralexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f05cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import pyproj\n",
    "from warnings import filterwarnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    ")\n",
    "import shap\n",
    "import folium\n",
    "from branca.element import Figure\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "sys.tracebacklimit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c88893",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_projeto = Path(os.getcwd()).parent.absolute().parent.absolute()\n",
    "data_dir = Path(dir_projeto, \"Output\", \"tcc\", \"v1\")\n",
    "shp_dir = Path(data_dir, \"shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ee4bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arredondamento de casas decimais para conversão de coordenadas geográficas\n",
    "arredondamento = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea14318",
   "metadata": {},
   "source": [
    "## funções"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55fb867",
   "metadata": {},
   "source": [
    "### coordenadas geográficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def utm_to_latlon(\n",
    "    df: pd.DataFrame,\n",
    "    x_col: str = \"X\",\n",
    "    y_col: str = \"Y\",\n",
    "    utm_zone: int = 22,\n",
    "    southern_hemisphere: bool = True,\n",
    "    arredondamento: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert UTM coordinates to latitude/longitude (WGS84)\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing coordinates\n",
    "    - x_col: Column name for easting (UTM X)\n",
    "    - y_col: Column name for northing (UTM Y)\n",
    "    - utm_zone: UTM zone number (Brazil is mostly zones 22-25)\n",
    "    - southern_hemisphere: True for southern hemisphere (Brazil)\n",
    "\n",
    "    Returns:\n",
    "    DataFrame with new 'longitude' and 'latitude' columns\n",
    "    \"\"\"\n",
    "    # Create UTM coordinate system\n",
    "    utm = pyproj.Proj(proj=\"utm\", zone=utm_zone, south=southern_hemisphere)\n",
    "\n",
    "    # Create WGS84 coordinate system\n",
    "    wgs84 = pyproj.Proj(proj=\"latlong\", datum=\"WGS84\")\n",
    "\n",
    "    # Convert coordinates\n",
    "    lon, lat = pyproj.transform(utm, wgs84, df[x_col].values, df[y_col].values)\n",
    "\n",
    "    # Add to DataFrame\n",
    "    df = df.copy()\n",
    "    df[\"longitude\"] = lon\n",
    "    df[\"latitude\"] = lat\n",
    "\n",
    "    df[\"longitude\"] = df[\"longitude\"].round(arredondamento)\n",
    "    df[\"latitude\"] = df[\"latitude\"].round(arredondamento)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_shapefile_to_latlon(shapefile_path: Path) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Read a shapefile and convert coordinates to latitude/longitude (WGS84)\n",
    "\n",
    "    Parameters:\n",
    "    - shapefile_path: path for the shapefile\n",
    "\n",
    "    Returns:\n",
    "    GeoDataFrame\n",
    "    \"\"\"\n",
    "    gdf = gpd.read_file(shapefile_path)\n",
    "    if gdf.crs is None:\n",
    "        # Assuming it's in the same UTM as your other data\n",
    "        gdf.crs = \"+proj=utm +zone=22 +south +datum=WGS84 +units=m +no_defs\"\n",
    "    gdf = gdf.to_crs(epsg=4326)  # Convert to WGS84 (lat/lon)\n",
    "    if not os.path.basename(shapefile_path) == \"estruturas_ln.shp\":\n",
    "        gdf[\"longitude\"] = gdf.geometry.x\n",
    "        gdf[\"latitude\"] = gdf.geometry.y\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d48f6",
   "metadata": {},
   "source": [
    "### processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterizar_coordenadas_geograficas(df: pd.DataFrame, n_clusters: np.int16 = 8) -> pd.DataFrame:\n",
    "    \"\"\"Aplica clusterização nas coordenadas geográficas para modelo de aprendizado de máquina,\n",
    "    como feature engineering\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe com dados de coordenadas geográficas\n",
    "        n_clusters (np.int16, optional): número de clusters. Defaults to 8.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe com clusters de coordenadas\n",
    "    \"\"\"\n",
    "    coords = df[[\"longitude\", \"latitude\"]].values\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(coords)\n",
    "    df[\"geo_cluster\"] = kmeans.labels_\n",
    "    dict_map_idx_lon = dict(zip(df.index, df[\"longitude\"]))\n",
    "    dict_map_idx_lat = dict(zip(df.index, df[\"latitude\"]))\n",
    "    df = df.drop([\"longitude\", \"latitude\"], axis=1)\n",
    "    return df, dict_map_idx_lon, dict_map_idx_lat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e62e14",
   "metadata": {},
   "source": [
    "### aprendizado de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3aad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size: np.float16 = 0.3) -> tuple:\n",
    "    \"\"\"Divide dados de treino e teste\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe com dados\n",
    "        test_size (np.float16, optional): tamanho dos dados de teste. Defaults to 0.3.\n",
    "\n",
    "    Returns:\n",
    "        tuple: _description_\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=test_size,\n",
    "        random_state=420,\n",
    "        stratify=y,  # dados desbalanceados\n",
    "    )\n",
    "\n",
    "    print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "    print(f\"Class balance - Train: {y_train.mean():.2%}, Test: {y_test.mean():.2%}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml(\n",
    "    models: dict,\n",
    "    cv: StratifiedKFold,\n",
    "    X_train: np.array,\n",
    "    X_test: np.array,\n",
    "    y_train: np.array,\n",
    "    y_test: np.array,\n",
    ") -> dict:\n",
    "    \"\"\"Pipeline para modelos de aprendizado de máquina, realizando treinamento com validação cruzada e avaliação\n",
    "\n",
    "    Args:\n",
    "        models (dict): dicionário com modelos\n",
    "        cv (StratifiedKFold): validação cruzada\n",
    "        X_train (np.array): array de dados independentes de treino\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_train (np.array): array de dados dependentes de treino\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline (scale for logistic regression)\n",
    "        if name == \"Logistic Regression\":\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            pipe = model\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipe, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipe.fit(X_train, y_train)\n",
    "\n",
    "        print(\"\\n\")\n",
    "        print(f\"Tempo total de treino {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\"model\": pipe, \"cv_mean_auc\": cv_scores.mean(), \"cv_std_auc\": cv_scores.std()}\n",
    "\n",
    "        print(f\"{name} - CV AUC: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "\n",
    "        # Evaluate on test set\n",
    "        if hasattr(pipe, \"predict_proba\"):\n",
    "            evaluate_model(pipe, X_test, y_test)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: np.array, y_test: np.array) -> None:\n",
    "    \"\"\"Função para avaliar o modelo\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred):.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\nOptimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def evaluate_model_custom(model, X_test: np.array, y_test: np.array, threshold: float) -> None:\n",
    "    \"\"\"Função para avaliar o modelo\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        X_test (np.array): array de dados independentes de teste\n",
    "        y_test (np.array): array de dados dependentes de teste\n",
    "    \"\"\"\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred_custom = (y_proba >= threshold).astype(int)\n",
    "\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.3f}\")\n",
    "    print(f\"F1 Score: {f1_score(y_test, y_pred_custom):.3f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred_custom))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "    f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "    optimal_idx = np.argmax(f1_scores)\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    print(f\"\\nOptimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_undersampling(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "    # Training and evaluation\n",
    "    for name, pipeline in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(f\"Tempo total de treino {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"model\": pipeline,\n",
    "            \"cv_mean_auc\": cv_scores.mean(),\n",
    "            \"cv_std_auc\": cv_scores.std(),\n",
    "        }\n",
    "\n",
    "        # Test set evaluation\n",
    "        if hasattr(pipeline, \"predict_proba\"):\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "            print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "            print(f\"Test F1 Score: {f1:.3f}\")\n",
    "            print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Find optimal threshold\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "            # Store additional metrics\n",
    "            results[name].update({\n",
    "                \"test_roc_auc\": roc_auc,\n",
    "                \"test_f1\": f1,\n",
    "                \"test_avg_precision\": avg_precision,\n",
    "                \"optimal_threshold\": optimal_threshold,\n",
    "            })\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "        print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "        print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "        print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd45f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_oversampling(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    min_minority_samples = min([\n",
    "        np.sum(y_train[test_idx] == 1) for _, test_idx in cv.split(X_train, y_train)\n",
    "    ])\n",
    "\n",
    "    k_neighbors = min(5, min_minority_samples - 1) if min_minority_samples > 1 else 1\n",
    "\n",
    "    # Training and evaluation\n",
    "    for name, model in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline with SMOTE\n",
    "        pipeline = ImbPipeline([\n",
    "            (\"smote\", SMOTE(random_state=42, sampling_strategy=\"auto\", k_neighbors=k_neighbors)),\n",
    "            (\"classifier\", model),\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            # Cross-validation\n",
    "            cv_scores = cross_val_score(\n",
    "                pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1, error_score=\"raise\"\n",
    "            )\n",
    "\n",
    "            # Full training\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "            print(f\"Training time {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\")\n",
    "\n",
    "            # Store results\n",
    "            results[name] = {\n",
    "                \"model\": pipeline,\n",
    "                \"cv_mean_auc\": cv_scores.mean(),\n",
    "                \"cv_std_auc\": cv_scores.std(),\n",
    "            }\n",
    "\n",
    "            print(f\"CV AUC: {cv_scores.mean():.3f} (±{cv_scores.std():.3f})\")\n",
    "\n",
    "            # Test set evaluation\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "\n",
    "                # Calculate metrics\n",
    "                roc_auc = roc_auc_score(y_test, y_proba)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "                print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "                print(f\"Test F1 Score: {f1:.3f}\")\n",
    "                print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "                print(\"\\nClassification Report:\")\n",
    "                print(classification_report(y_test, y_pred))\n",
    "\n",
    "                # Find optimal threshold\n",
    "                precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "                f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "                optimal_idx = np.argmax(f1_scores)\n",
    "                optimal_threshold = thresholds[optimal_idx]\n",
    "                print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "                # Store additional metrics\n",
    "                results[name].update({\n",
    "                    \"test_roc_auc\": roc_auc,\n",
    "                    \"test_f1\": f1,\n",
    "                    \"test_avg_precision\": avg_precision,\n",
    "                    \"optimal_threshold\": optimal_threshold,\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to train {name}: {str(e)}\")\n",
    "            results[name] = {\"error\": str(e)}\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        if \"error\" in res:\n",
    "            print(f\"Training failed: {res['error']}\")\n",
    "        else:\n",
    "            print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "            if \"test_roc_auc\" in res:\n",
    "                print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "                print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "                print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80667d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_ml_smote_tomek(pipelines, cv, X_train, X_test, y_train, y_test) -> dict:\n",
    "    results = {}\n",
    "\n",
    "    # Training and evaluation\n",
    "    for name, model in pipelines.items():\n",
    "        print(f\"\\n=== Training {name} ===\")\n",
    "\n",
    "        start_train = time.perf_counter()\n",
    "\n",
    "        # Create pipeline with SMOTETomek\n",
    "        pipeline = ImbPipeline([\n",
    "            (\n",
    "                \"smote_tomek\",\n",
    "                SMOTETomek(\n",
    "                    random_state=42,\n",
    "                    tomek=TomekLinks(sampling_strategy=\"majority\"),\n",
    "                    smote=SMOTE(k_neighbors=2),  # Reduce from default 5\n",
    "                ),\n",
    "            ),\n",
    "            (\"classifier\", model),\n",
    "        ])\n",
    "\n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "        # Full training\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        print(\n",
    "            f\"Total training time for {name}: {round((time.perf_counter() - start_train) / 60, 2)} min\"\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            \"model\": pipeline,\n",
    "            \"cv_mean_auc\": cv_scores.mean(),\n",
    "            \"cv_std_auc\": cv_scores.std(),\n",
    "        }\n",
    "\n",
    "        # Test set evaluation\n",
    "        if hasattr(model, \"predict_proba\"):  # Check the original model for predict_proba\n",
    "            y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "\n",
    "            # Calculate metrics\n",
    "            roc_auc = roc_auc_score(y_test, y_proba)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "            print(f\"Test ROC-AUC: {roc_auc:.3f}\")\n",
    "            print(f\"Test F1 Score: {f1:.3f}\")\n",
    "            print(f\"Test Average Precision: {avg_precision:.3f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "\n",
    "            # Find optimal threshold\n",
    "            precision, recall, thresholds = precision_recall_curve(y_test, y_proba)\n",
    "            f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "            optimal_idx = np.argmax(f1_scores)\n",
    "            optimal_threshold = thresholds[optimal_idx]\n",
    "            print(f\"Optimal Decision Threshold: {optimal_threshold:.3f}\")\n",
    "\n",
    "            # Store additional metrics\n",
    "            results[name].update({\n",
    "                \"test_roc_auc\": roc_auc,\n",
    "                \"test_f1\": f1,\n",
    "                \"test_avg_precision\": avg_precision,\n",
    "                \"optimal_threshold\": optimal_threshold,\n",
    "            })\n",
    "\n",
    "    # Compare model performance\n",
    "    print(\"\\n=== Model Comparison ===\")\n",
    "    for name, res in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"CV AUC: {res['cv_mean_auc']:.3f} (±{res['cv_std_auc']:.3f})\")\n",
    "        if \"test_roc_auc\" in res:\n",
    "            print(f\"Test ROC-AUC: {res['test_roc_auc']:.3f}\")\n",
    "            print(f\"Test F1: {res['test_f1']:.3f}\")\n",
    "            print(f\"Optimal Threshold: {res['optimal_threshold']:.3f}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed50d07",
   "metadata": {},
   "source": [
    "## leitura e processamento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3075ed",
   "metadata": {},
   "source": [
    "- leitura dos shapefiles com ocorrências de metais/minas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38260a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouro = gpd.read_file(Path(shp_dir, 'ocorrencias_Au.shp'))\n",
    "# # cobre = gpd.read_file(Path(shp_dir, 'ocorrencias_Cu.shp'))\n",
    "# ferro = gpd.read_file(Path(shp_dir, 'ocorrencias_Fe.shp'))\n",
    "# # manganes = gpd.read_file(Path(shp_dir, 'ocorrencias_Mn.shp'))\n",
    "# # niquel = gpd.read_file(Path(shp_dir, 'ocorrencias_Ni.shp'))\n",
    "# # chumbo = gpd.read_file(Path(shp_dir, 'ocorrencias_Pb.shp'))\n",
    "# # estanho = gpd.read_file(Path(shp_dir, 'ocorrencias_Sn.shp'))\n",
    "# minas = gpd.read_file(Path(shp_dir, 'minas.shp'))\n",
    "# estruturas = gpd.read_file(Path(shp_dir, 'estruturas_ln.shp'))\n",
    "\n",
    "# ! leitura dos arquivos com conversão para latitude/longitude\n",
    "ouro = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Au.shp\"))\n",
    "cobre = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Cu.shp\"))\n",
    "ferro = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Fe.shp\"))\n",
    "# manganes = convert_shapefile_to_latlon(Path(shp_dir, 'ocorrencias_Mn.shp'))\n",
    "niquel = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Ni.shp\"))\n",
    "chumbo = convert_shapefile_to_latlon(Path(shp_dir, \"ocorrencias_Pb.shp\"))\n",
    "# estanho = convert_shapefile_to_latlon(Path(shp_dir, 'ocorrencias_Sn.shp'))\n",
    "\n",
    "minas = convert_shapefile_to_latlon(Path(shp_dir, \"minas.shp\"))\n",
    "\n",
    "estruturas = convert_shapefile_to_latlon(Path(shp_dir, \"estruturas_ln.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34065dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://matplotlib.org/stable/api/markers_api.html\n",
    "# https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ouro.plot(ax=ax, color=\"orange\", marker=\"*\", markersize=50, label=\"Ouro\")\n",
    "cobre.plot(ax=ax, color=\"lightcoral\", marker=\"x\", markersize=50, label=\"Cobre\")\n",
    "ferro.plot(ax=ax, color=\"gray\", marker=\"v\", markersize=50, label=\"Ferro\")\n",
    "chumbo.plot(ax=ax, color=\"lightsteelblue\", marker=\"s\", markersize=50, label=\"Chumbo\")\n",
    "niquel.plot(ax=ax, color=\"green\", marker=\"p\", markersize=50, label=\"Níquel\")\n",
    "minas.plot(ax=ax, color=\"blue\", marker=\"o\", markersize=50, label=\"Minas\")\n",
    "# estruturas.plot(ax=ax, color='blue', alpha=0.5, label='Estruturas')\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5899c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minas = pd.DataFrame(minas)\n",
    "df_minas = df_minas[[\"longitude\", \"latitude\"]]\n",
    "df_minas[\"longitude\"] = df_minas[\"longitude\"].round(arredondamento)\n",
    "df_minas[\"latitude\"] = df_minas[\"latitude\"].round(arredondamento)\n",
    "\n",
    "df_minas.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ouro, cobre, ferro, manganes, niquel, chumbo, estanho\n",
    "df_minerio = pd.DataFrame(cobre)\n",
    "df_minerio = df_minerio[[\"longitude\", \"latitude\"]]\n",
    "df_minerio[\"longitude\"] = df_minerio[\"longitude\"].round(arredondamento)\n",
    "df_minerio[\"latitude\"] = df_minerio[\"latitude\"].round(arredondamento)\n",
    "df_minerio = df_minerio.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "df_minerio[\"ocorrencia\"] = 1\n",
    "\n",
    "print(df_minerio.shape)\n",
    "df_minerio.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb4c85b",
   "metadata": {},
   "source": [
    "- leitura dos dados de espectrometria\n",
    "\n",
    "  - dados:\n",
    "    - Fator F: parâmetro de Efimov (valores altos para rochas alteradas por fluidos que carregam metais)\n",
    "    - Kd: abundância de potássio normalizado pelo tório\n",
    "    - Ud: abundância de urânio normalizado pelo tório"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d653214",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_data = pd.read_csv(\n",
    "    Path(data_dir, \"dados_gamaespectrometria_filtrados.csv\"),\n",
    "    dtype={\n",
    "        \"XUTM\": np.float32,\n",
    "        \"YUTM\": np.float32,\n",
    "        \"FatorF\": np.float32,\n",
    "        \"Kd\": np.float32,\n",
    "        \"Ud\": np.float32,\n",
    "    },\n",
    ")\n",
    "# spec_data.rename(columns={\"XUTM\": \"X\", \"YUTM\": \"Y\"}, inplace=True)\n",
    "spec_data = utm_to_latlon(spec_data, x_col=\"XUTM\", y_col=\"YUTM\", arredondamento=arredondamento)\n",
    "spec_data = spec_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "spec_data = spec_data.drop([\"XUTM\", \"YUTM\"], axis=1)\n",
    "print(spec_data.shape)\n",
    "spec_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c076fd34",
   "metadata": {},
   "source": [
    "- leitura dos dados de gravimetria\n",
    "\n",
    "  - dados:\n",
    "    - grav_residual190km_qht: gravidade residual a 190 km\n",
    "    - grav_residual100km: gravidade residual a 100 km\n",
    "    - maq_asvi: amplitude do sinal analítico da integral vertical do campo magnético\n",
    "    - maq_qt: gradiente total do campo magnético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc9b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "grav_data = pd.read_csv(\n",
    "    Path(data_dir, \"dados_gravmag_filtrados_v2.csv\"),\n",
    "    dtype={\n",
    "        \"X\": np.float32,\n",
    "        \"Y\": np.float32,\n",
    "        \"grav_residual190km_ght\": np.float32,\n",
    "        \"grav_residual100km\": np.float32,\n",
    "        \"mag_asvi\": np.float32,\n",
    "        \"mag_gt\": np.float32,\n",
    "    },\n",
    ")\n",
    "grav_data = utm_to_latlon(grav_data, x_col=\"X\", y_col=\"Y\", arredondamento=arredondamento)\n",
    "grav_data = grav_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "grav_data = grav_data.drop([\"X\", \"Y\"], axis=1)\n",
    "print(grav_data.shape)\n",
    "grav_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ee24b1",
   "metadata": {},
   "source": [
    "- mesclar dfs com dados de gravimetria e espectrometria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_data = pd.merge(spec_data, grav_data, how=\"inner\", on=[\"longitude\", \"latitude\"])\n",
    "df_merge_data = df_merge_data[\n",
    "    [\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"FatorF\",\n",
    "        \"Kd\",\n",
    "        \"Ud\",\n",
    "        \"grav_residual190km_ght\",\n",
    "        \"grav_residual100km\",\n",
    "        \"mag_asvi\",\n",
    "        \"mag_gt\",\n",
    "    ]\n",
    "]\n",
    "df_merge_data = df_merge_data.drop_duplicates(subset=['longitude', 'latitude'])\n",
    "print(df_merge_data.shape)\n",
    "df_merge_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadcc16a",
   "metadata": {},
   "source": [
    "- criar dataframes base para aprendizado de máquina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! aplica knn para pontos de ocorrência de ouro mais próximos\n",
    "# coords_merge = df_merge_data_reduced[[\"longitude\", \"latitude\"]].values\n",
    "# coords_minerio = df_minerio[[\"longitude\", \"latitude\"]].values\n",
    "\n",
    "# nbrs = NearestNeighbors(n_neighbors=1).fit(coords_merge)\n",
    "# distances, indices = nbrs.kneighbors(coords_minerio)\n",
    "\n",
    "# df_minerio_merge = df_merge_data_reduced.copy()\n",
    "# df_minerio_merge[\"ocorrencia\"] = 0\n",
    "\n",
    "# for pos in indices.flatten():\n",
    "#     df_minerio_merge.loc[pos, \"ocorrencia\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4736c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape do merge == df_minerio -> garantia de que há os mesmos pontos\n",
    "pd.merge(df_merge_data, df_minerio, how=\"inner\", on=[\"longitude\", \"latitude\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80cba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria df com inner join\n",
    "df_minerio_inner = pd.merge(df_merge_data, df_minerio, how=\"inner\", on=[\"longitude\", \"latitude\"])\n",
    "print(df_minerio_inner.shape)\n",
    "df_minerio_inner.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c10ef2",
   "metadata": {},
   "source": [
    "- Muitos pontos na base de dados -> desbalanço muito forte de classes\n",
    "    - Redução da base: corte da área e reamostragem da base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f49d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mesclagem de dados (espec + gravim): {df_merge_data.shape[0]}\")\n",
    "print(f\"Mesclagem de dados (espec + gravim): {df_minerio.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360a2a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(df_merge_data['longitude'], df_merge_data['latitude'], label='Grade Mescalada')\n",
    "ax.scatter(df_minerio['longitude'], df_minerio['latitude'], color='lightcoral', label='Ocorrências de Cobre')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6e704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redução da área geográfica\n",
    "min_lat, max_lat = df_minerio['latitude'].min(), df_minerio['latitude'].max()\n",
    "min_lon, max_lon = df_minerio['longitude'].min(), df_minerio['longitude'].max()\n",
    "\n",
    "padding = 0.1\n",
    "lat_min_padded = min_lat - padding\n",
    "lat_max_padded = max_lat + padding\n",
    "lon_min_padded = min_lon - padding\n",
    "lon_max_padded = max_lon + padding\n",
    "\n",
    "df_merge_data_clipped = df_merge_data[\n",
    "    (df_merge_data['latitude'] >= lat_min_padded) & (df_merge_data['latitude'] <= lat_max_padded) &\n",
    "    (df_merge_data['longitude'] >= lon_min_padded) & (df_merge_data['longitude'] <= lon_max_padded)\n",
    "]\n",
    "\n",
    "# reamostragem dos dados via pandas\n",
    "df_merge_data_reduced = df_merge_data_clipped.sample(frac=0.03, random_state=42)\n",
    "\n",
    "print(df_merge_data_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f751bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatena inner join com reamostragem\n",
    "df_minerio_merge = pd.concat([df_merge_data_reduced, df_minerio_inner], axis=0, ignore_index=True)\n",
    "df_minerio_merge = df_minerio_merge.fillna(0)\n",
    "df_minerio_merge['ocorrencia'] = df_minerio_merge['ocorrencia'].astype(int)\n",
    "print(df_merge_data_reduced.shape)\n",
    "df_minerio_merge.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75203b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.scatter(\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 0][\"longitude\"],\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 0][\"latitude\"],\n",
    "    label=\"Grade Mescalada\",\n",
    ")\n",
    "ax.scatter(\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 1][\"longitude\"],\n",
    "    df_minerio_merge[df_minerio_merge[\"ocorrencia\"] == 1][\"latitude\"],\n",
    "    color=\"lightcoral\",\n",
    "    label=\"Ocorrências de Cobre\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890761de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dados de espectrometria: {spec_data.shape[0]}\")\n",
    "print(f\"Dados de gravimetria: {grav_data.shape[0]}\")\n",
    "print(f\"Mesclagem de dados (espec + gravim): {df_merge_data.shape[0]}\")\n",
    "print(f\"Redução de mesclagem de dados (espec + gravim): {df_merge_data_reduced.shape[0]}\")\n",
    "print(f\"Mesclagem com cobre (espec + gravim + cobre): {df_minerio_merge.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3e29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 4))\n",
    "ax = sns.countplot(x=\"ocorrencia\", data=df_minerio_merge, palette=\"pastel\")\n",
    "for i in ax.containers:\n",
    "    ax.bar_label(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ea6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Cobre:\",\n",
    "    round(df_minerio_merge[\"ocorrencia\"].value_counts()[1] / len(df_minerio_merge) * 100, 2),\n",
    "    \"% do dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a922109b",
   "metadata": {},
   "source": [
    "- clusterização de coordenadas geográficas\n",
    "  - n_clusters = default 8 (tutorial) -> parametrizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175cf925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minerio_merge, dict_map_idx_lon, dict_map_idx_lat = clusterizar_coordenadas_geograficas(\n",
    "    df=df_minerio_merge\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e821f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_minerio_merge = df_minerio_merge[\n",
    "    [\n",
    "        \"geo_cluster\",\n",
    "        \"FatorF\",\n",
    "        \"Kd\",\n",
    "        \"Ud\",\n",
    "        \"grav_residual190km_ght\",\n",
    "        \"grav_residual100km\",\n",
    "        \"mag_asvi\",\n",
    "        \"mag_gt\",\n",
    "        \"ocorrencia\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975c2c4",
   "metadata": {},
   "source": [
    "## aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4e8eec",
   "metadata": {},
   "source": [
    "### split treino-teste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8724df17",
   "metadata": {},
   "source": [
    "- split padrão -> 70% treino e 30% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2adf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_minerio_merge.drop([\"ocorrencia\"], axis=1)\n",
    "y = df_minerio_merge[\"ocorrencia\"].values\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e500fbd",
   "metadata": {},
   "source": [
    "### pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "results = pipeline_ml(models, cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e2539f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Teve o melhor F1-score entre os modelos (0.756 CV AUC), mas ainda assim falhou completamente em prever a classe 1 (F1=0).\n",
    "\n",
    "    - A alta precisão para a classe 0 (96%) com recall perfeito (100%) indica que o modelo está simplesmente classificando tudo como classe 0.\n",
    "\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Mostrou algum poder preditivo para a classe 1 (recall=69%), mas com precisão muito baixa (7%).\n",
    "\n",
    "    - O threshold ótimo foi o mais alto (0.593), sugerindo que o modelo é conservador.\n",
    "\n",
    "\n",
    "- SVM (Support Vector Machine)\n",
    "\n",
    "    - Teve o pior desempenho geral (AUC=0.581), com comportamento errático (alto recall mas baixíssima precisão para classe 1).\n",
    "\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - Obteve o melhor ROC-AUC (0.817) na validação, mas ainda com desempenho ruim na classe 1 (F1=0.105).\n",
    "\n",
    "    - Mostrou o melhor equilíbrio entre as métricas, mas ainda insuficiente.\n",
    "\n",
    "---\n",
    "\n",
    "- Problema Principal: Desbalanceamento de Classes\n",
    "\n",
    "    - O principal problema parece ser o desequilíbrio extremo das classes. Técnicas como oversampling da classe minoritária, undersampling da classe majoritária ou uso de pesos de classe podem ajudar.\n",
    "\n",
    "    - Ajuste fino dos thresholds de classificação pode melhorar o F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cd8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(1, 4, figsize=(10, 4))\n",
    "# for mdl, ax in zip(models.keys(), axs.flatten()):\n",
    "#     y_proba = models[mdl].predict_proba(X_test)[:, 1]\n",
    "#     fpr, tpr, threshold = roc_curve(y_test, y_proba)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#     # plot\n",
    "#     ax.plot(fpr, tpr, label=\"AUC={}\".format(round(roc_auc, 2)))\n",
    "#     ax.plot([0, 1], [0, 1], \"r--\")\n",
    "#     ax.legend()\n",
    "#     ax.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "#     ax.set_title(mdl)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb24f2",
   "metadata": {},
   "source": [
    "- Soluções:\n",
    "  - Existem diferentes soluções:\n",
    "    - undersampling da classe majoritária (0)\n",
    "    - oversampling da classe minoritária (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc0be2",
   "metadata": {},
   "source": [
    "### pipeline undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13f260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Create pipelines with undersampling\n",
    "pipelines_unders = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Adiciona StandardScaler para modelos sensíveis à escala\n",
    "        pipelines_unders[name] = make_pipeline(\n",
    "            RandomUnderSampler(random_state=42), StandardScaler(), model\n",
    "        )\n",
    "    else:\n",
    "        pipelines_unders[name] = make_pipeline(RandomUnderSampler(random_state=42), model)\n",
    "\n",
    "results_unders = pipeline_ml_undersampling(pipelines_unders, cv, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fdde3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Melhor desempenho geral (ROC-AUC: 0.763 / F1-Score: 0.162 para classe 1).\n",
    "\n",
    "    - Recall alto para classe 1 (69%), mas precisão muito baixa (9%) – muitos falsos positivos.\n",
    "\n",
    "    - Threshold alto (0.88) indica que o modelo só classifica como \"1\" quando tem alta confiança.\n",
    "\n",
    "    - AUC consistente (CV: 0.757 ± 0.066), mostrando robustez.\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Desempenho moderado (ROC-AUC: 0.744 / F1-Score: 0.113).\n",
    "\n",
    "    - Recall razoável (62%), mas precisão extremamente baixa (6%) – quase inútil na prática.\n",
    "\n",
    "    - Threshold mais baixo (0.585), refletindo menor confiança nas previsões.\n",
    "\n",
    "    - AUC estável (CV: 0.700 ± 0.070), porém ainda limitado.\n",
    "\n",
    "- SVM\n",
    "\n",
    "    - Resultados similares ao Random Forest (ROC-AUC: 0.735 / F1-Score: 0.133).\n",
    "\n",
    "    - Recall aceitável (54%), mas precisão muito baixa (8%).\n",
    "\n",
    "    - Threshold intermediário (0.639), equilibrando um pouco mais as classes.\n",
    "\n",
    "    - Alta variabilidade no CV AUC (±0.096), indicando sensibilidade aos dados.\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - Melhor ROC-AUC (0.779), mas F1-Score baixo (0.114) devido à precisão péssima (6%).\n",
    "\n",
    "    - Recall altíssimo (77%), mas com muitos falsos positivos (precisão inaceitável).\n",
    "\n",
    "    - Threshold extremamente alto (0.988), sugerindo que o modelo quase nunca prevê \"1\".\n",
    "\n",
    "    - Alta variabilidade no CV (±0.120), possivelmente devido ao desbalanceamento residual.\n",
    "\n",
    "---\n",
    "\n",
    "- Problemas Identificados\n",
    "\n",
    "    - Trade-off entre Recall e Precisão\n",
    "\n",
    "        - Todos os modelos priorizaram recall para a classe 1, mas com precisão muito baixa (6–9%).\n",
    "\n",
    "        - Isso gera muitos falsos positivos, inviabilizando o uso em cenários reais (ex.: custo alto de ações baseadas em previsões erradas).\n",
    "\n",
    "    - Thresholds Otimizados, mas Insuficientes\n",
    "\n",
    "        - Ajustar o threshold melhorou o recall, mas não resolveu a baixa precisão.\n",
    "\n",
    "        - XGBoost teve o pior caso: threshold = 0.988 praticamente ignora a classe 1.\n",
    "\n",
    "    - Undersampling Pode Ter Removido Informação Relevante\n",
    "\n",
    "        - A redução da classe majoritária pode ter eliminado padrões importantes, afetando a generalização.\n",
    "\n",
    "        - Alternativas: Testar SMOTE (oversampling) ou abordagens híbridas.\n",
    "\n",
    "    - AUC Alto ≠ Desempenho Prático\n",
    "\n",
    "        - XGBoost teve o melhor AUC (0.779), mas não se traduziu em F1-Score útil.\n",
    "\n",
    "        - Métrica mais relevante: Average Precision (AP) – todos os modelos tiveram AP < 0.2, confirmando a dificuldade com a classe 1.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686bc9c",
   "metadata": {},
   "source": [
    "### pipeline oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Create pipelines with overrsampling\n",
    "pipelines_overs = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Add StandardScaler for Logistic Regression\n",
    "        pipelines_overs[name] = make_pipeline(StandardScaler(), model)\n",
    "    else:\n",
    "        pipelines_overs[name] = make_pipeline(model)\n",
    "\n",
    "results_overs = pipeline_ml_oversampling(\n",
    "    pipelines=pipelines_overs, cv=cv, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91175337",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Melhora no F1-Score (0.250 vs 0.162 com undersampling), mas ainda precisão baixa (27%) para classe 1.\n",
    "\n",
    "    - Recall piorou (23% vs 69% com undersampling), indicando que o SMOTE pode ter introduzido ruído.\n",
    "\n",
    "    - AUC razoável (0.731), mas com alta variabilidade no CV (±0.130).\n",
    "\n",
    "    - Threshold mais baixo (0.72), mostrando maior disposição a prever classe 1.\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Pior desempenho geral (F1-Score: 0.113 / ROC-AUC: 0.690).\n",
    "\n",
    "    - Recall alto (62%), mas precisão catastrófica (6%) – quase inútil na prática.\n",
    "\n",
    "    - Threshold baixo (0.566) reflete baixa confiança nas previsões.\n",
    "\n",
    "    - AUC consistentemente baixo (CV: 0.648), indicando incapacidade de aprender padrões complexos.\n",
    "\n",
    "- SVM\n",
    "\n",
    "    - Melhor F1-Score (0.273) entre todos, com recall aceitável (69%) e precisão melhor (17%).\n",
    "\n",
    "    - ROC-AUC excelente (0.863), sugerindo boa capacidade discriminativa.\n",
    "\n",
    "    - Threshold equilibrado (0.68), mas ainda com muitos falsos positivos.\n",
    "\n",
    "    - Alta variabilidade no CV (±0.130), exigindo validação cruzada rigorosa.\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - AUC alto (0.803), mas F1-Score mediano (0.238) devido à precisão ruim (17%).\n",
    "\n",
    "    - Recall razoável (38%), mas threshold extremo (0.996) – praticamente só prevê classe 1 com certeza absoluta.\n",
    "\n",
    "    - CV AUC alto (0.780), porém com alta variabilidade (±0.146), indicando instabilidade.\n",
    "\n",
    "---\n",
    "\n",
    "- O oversampling com SMOTE melhorou a detecção da classe 1, especialmente no SVM (F1: 0.273, ROC-AUC: 0.863). No entanto:\n",
    "\n",
    "    - Precisão ainda é baixa (17–27%), o que pode ser inviável em cenários reais.\n",
    "\n",
    "    - XGBoost e Random Forest tiveram desempenho irregular, com trade-offs claros.\n",
    "\n",
    "    - Próximos passos: Otimizar SMOTE, testar ensembles híbridos e focar no SVM como modelo promissor.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a80bbec",
   "metadata": {},
   "source": [
    "### pipeline combinação oversampling + undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c987e",
   "metadata": {},
   "source": [
    "Ref: https://www.kaggle.com/code/marcinrutecki/best-techniques-and-metrics-for-imbalanced-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        class_weight=\"balanced\", max_iter=1000, random_state=42, penalty=\"l2\", solver=\"lbfgs\"\n",
    "    ),\n",
    "    \"SVM\": SVC(\n",
    "        class_weight=\"balanced\",\n",
    "        kernel=\"rbf\",\n",
    "        C=1.0,\n",
    "        gamma=\"scale\",\n",
    "        probability=True,\n",
    "        random_state=42,\n",
    "    ),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]),\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric=\"logloss\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "pipelines_comb = {}\n",
    "for name, model in models.items():\n",
    "    if name in {\"Logistic Regression\", \"SVM\"}:\n",
    "        # Add StandardScaler for Logistic Regression\n",
    "        pipelines_comb[name] = make_pipeline(StandardScaler(), model)\n",
    "    else:\n",
    "        pipelines_comb[name] = make_pipeline(model)\n",
    "\n",
    "results_smote_tomek = pipeline_ml_smote_tomek(\n",
    "    pipelines=pipelines_comb, cv=cv, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd448d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Random Forest\n",
    "\n",
    "    - Melhor F1-Score até agora (0.286 vs 0.250 com SMOTE)\n",
    "\n",
    "    - Precisão da classe 1 melhorou (38% vs 27%), mas recall caiu (23% vs 23% mantido)\n",
    "\n",
    "    - Threshold baixo (0.48) mostra maior sensibilidade à classe minoritária\n",
    "\n",
    "    - AUC estável (0.750) com menor variabilidade (±0.109 vs ±0.130)\n",
    "\n",
    "- Regressão Logística\n",
    "\n",
    "    - Pior modelo consistentemente (F1: 0.128, AUC: 0.637)\n",
    "\n",
    "    - Recall artificialmente alto (69%) com precisão catastrófica (7%)\n",
    "\n",
    "    - Threshold próximo de 0.5 (0.501) indica decisões quase aleatórias\n",
    "\n",
    "    - Inviável para uso prático\n",
    "\n",
    "- SVM\n",
    "\n",
    "    - Melhor desempenho global (F1: 0.321, ROC-AUC: 0.875)\n",
    "\n",
    "    - Maior recall útil (69%) com precisão aceitável (21%)\n",
    "\n",
    "    - Threshold equilibrado (0.729)\n",
    "\n",
    "    - AP (0.366) quase 2x maior que Random Forest\n",
    "\n",
    "    - Modelo mais promissor para otimização\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "    - Desempenho mediano (F1: 0.222, AUC: 0.762)\n",
    "\n",
    "    - Precisão ruim (17%) com recall moderado (31%)\n",
    "\n",
    "    - Threshold extremo (0.96) revela excessiva cautela\n",
    "\n",
    "    - Variabilidade alta (±0.134) sugere instabilidade\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f370c96c",
   "metadata": {},
   "source": [
    "### melhor modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04273f2",
   "metadata": {},
   "source": [
    "- fazendo uso apenas do modelo Random Forest + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ddce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42, n_jobs=-1)\n",
    "\n",
    "min_minority_samples = min([\n",
    "    np.sum(y_train[test_idx] == 1) for _, test_idx in cv.split(X_train, y_train)\n",
    "])\n",
    "\n",
    "k_neighbors = min(5, min_minority_samples - 1) if min_minority_samples > 1 else 1\n",
    "\n",
    "pipeline = ImbPipeline([\n",
    "    (\"smote\", SMOTE(random_state=42, sampling_strategy=\"auto\", k_neighbors=k_neighbors)),\n",
    "    (\"classifier\", model),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "print('Pipeline Sem Threshold Ótimo')\n",
    "evaluate_model(pipeline, X_test, y_test)\n",
    "\n",
    "print('\\nPipeline Com Threshold Ótimo')\n",
    "# Apply threshold\n",
    "# Optimal Decision Threshold: 0.996\n",
    "evaluate_model_custom(pipeline, X_test, y_test, 0.996)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45708f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "# Apply threshold\n",
    "# Optimal Decision Threshold: 0.550\n",
    "y_pred_custom = (y_proba >= 0.550).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2260151",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Class 1: {sum(y_pred == 0)}\")\n",
    "print(f\"Class 1 (Custom): {sum(y_pred_custom == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ddd913",
   "metadata": {},
   "source": [
    "- feature importance do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da0dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = pipeline.named_steps['classifier']\n",
    "\n",
    "importances = rf_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(\"Feature Importance\", fontsize=14)\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), feature_names[indices], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Gini Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot all this\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.plot(fpr, tpr, label=\"AUC={}\".format(round(roc_auc, 2)))\n",
    "ax.plot([0, 1], [0, 1], \"r--\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Best Model ROC-AUC\")\n",
    "ax.grid(visible=True, alpha=0.6, linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69974e",
   "metadata": {},
   "source": [
    "### SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9f586f",
   "metadata": {},
   "source": [
    "Ref: https://shap.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3ef3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns.tolist()\n",
    "\n",
    "explainer = shap.Explainer(rf_model)\n",
    "shap_values = explainer(X_train)\n",
    "shap_values_pos = shap_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d48433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Data shape: {X_train.shape}\")\n",
    "print(f\"All SHAP values shape: {np.array(shap_values).shape}\")\n",
    "print(f\"SHAP values for class 1: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values,\n",
    "    pd.DataFrame(X_train, columns=X_train.columns),\n",
    "    feature_names=X_train.columns.tolist(),\n",
    "    plot_type=\"bar\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7749b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values, pd.DataFrame(X_train, columns=X_train.columns), plot_type=\"violin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e4daed",
   "metadata": {},
   "source": [
    "### Mapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_df = pd.DataFrame.from_dict(dict_map_idx_lon, orient=\"index\")\n",
    "coord_df[\"latitude\"] = dict_map_idx_lat\n",
    "coord_df.columns = [\"longitude\", \"latitude\"]\n",
    "coord_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92444f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = X_test.copy()\n",
    "results[\"probability\"] = y_proba\n",
    "results[\"prediction\"] = y_pred_custom\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30265c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.merge(results, coord_df, left_index=True, right_index=True, how=\"inner\")\n",
    "results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d48abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mineral_locations = results[results[\"prediction\"] == 1]\n",
    "print(f\"Locais com alta confiança de cobre: {len(mineral_locations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6af9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python-visualization.github.io/folium/latest/user_guide/raster_layers/tiles.html\n",
    "fig = Figure(width=700, height=600)\n",
    "\n",
    "m = folium.Map(\n",
    "    location=[mineral_locations[\"latitude\"].mean(), mineral_locations[\"longitude\"].mean()],\n",
    "    zoom_start=7,\n",
    ")\n",
    "\n",
    "for _, row in df_minas.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]], radius=5, color=\"red\", fill=True, tooltip=\"Mina\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "for _, row in df_minerio.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]], radius=5, color=\"sienna\", fill=True, tooltip=\"Cobre\"\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "for _, row in mineral_locations.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row[\"latitude\"], row[\"longitude\"]],\n",
    "        radius=5,\n",
    "        color=\"lightcoral\",\n",
    "        fill=True,\n",
    "        tooltip=f\"Cobre Prob: {row['probability']:.3f}\",\n",
    "    ).add_to(m)\n",
    "\n",
    "\n",
    "fig.add_child(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
